Model, Mode,Server, Data_Type, Use_Case, Batch_Size, Result
resnet50;inference;SKX;fp32;Throughput;128;376.22;benchmark_resnet50_inference_aipg-ra-skx-51.log;tensorflow-skylake-benchmark-nightly;706
inception3;training;SKX;fp32;Throughput;64;59.83;benchmark_inception3_training_aipg-ra-skx-51.log;tensorflow-skylake-benchmark-nightly;706
inception3;inference;SKX;fp32;Throughput;64;330.26;benchmark_inception3_inference_aipg-ra-skx-51.log;tensorflow-skylake-benchmark-nightly;706
vgg16;training;SKX;fp32;Throughput;128;54.31;benchmark_vgg16_training_aipg-ra-skx-51.log;tensorflow-skylake-benchmark-nightly;706
vgg16;inference;SKX;fp32;Throughput;128;337.92;benchmark_vgg16_inference_aipg-ra-skx-51.log;tensorflow-skylake-benchmark-nightly;706
ds2;training;SKX;fp32;Throughput;;181.59;benchmark_ds2_training_aipg-ra-skx-51.log;tensorflow-skylake-benchmark-nightly;706
SSDvgg16;training;SKX;fp32;Throughput;;;benchmark_SSDvgg16_training_aipg-ra-skx-51.log;tensorflow-skylake-benchmark-nightly;706
SSDvgg16;inference;SKX;fp32;Throughput;224;;benchmark_SSDvgg16_inference_aipg-ra-skx-51_throughput.log;tensorflow-skylake-benchmark-nightly;706
SSDvgg16;inference;SKX;fp32;Latency;1;32.331;benchmark_SSDvgg16_inference_aipg-ra-skx-51_latency.log;tensorflow-skylake-benchmark-nightly;706
SSDvgg16;inference;SKX;fp32;Accuracy;224;0.651217,;benchmark_SSDvgg16_inference_aipg-ra-skx-51_accuracy.log;tensorflow-skylake-benchmark-nightly;706
mnist;training;SKX;fp32;Throughput;;accuracy: below expectation;benchmark_mnist_training_aipg-ra-skx-51.log;tensorflow-skylake-benchmark-nightly;706
resnet32cifar10;training;SKX;fp32;Accuracy;;0.8300781;benchmark_resnet32cifar10_training_aipg-ra-skx-51.log;tensorflow-skylake-benchmark-nightly;706
cifar10;training;SKX;fp32;Accuracy;;0.605;benchmark_cifar10_training_eval_aipg-ra-skx-51.log;tensorflow-skylake-benchmark-nightly;706
dcgan;training;SKX;fp32;Throughput;;46;benchmark_dcgan_training_aipg-ra-skx-51.log;tensorflow-skylake-benchmark-nightly;706
ResNet101;inference;SKX;int8;Throughput;128;309.788332189;benchmark_ResNet101_inference_aipg-ra-skx-52_throughput.log;Private-TensorFlow-Benchmark-Q4-Int8-Models;235
ResNet101;inference;SKX;int8;Latency;1;12.808;benchmark_ResNet101_inference_aipg-ra-skx-52_latency.log;Private-TensorFlow-Benchmark-Q4-Int8-Models;235
ResNet101;inference;SKX;int8;Accuracy;1;0.7567, 0.9269;benchmark_ResNet101_inference_aipg-ra-skx-52_accuracy.log;Private-TensorFlow-Benchmark-Q4-Int8-Models;235
InceptionV4;inference;SKX;int8;Throughput;240;177.253259603;benchmark_InceptionV4_inference_aipg-ra-skx-52_throughput.log;Private-TensorFlow-Benchmark-Q4-Int8-Models;235
InceptionV4;inference;SKX;int8;Latency;1;24.106;benchmark_InceptionV4_inference_aipg-ra-skx-52_latency.log;Private-TensorFlow-Benchmark-Q4-Int8-Models;235
InceptionV4;inference;SKX;int8;Accuracy;1;0.7989, 0.9507;benchmark_InceptionV4_inference_aipg-ra-skx-52_accuracy.log;Private-TensorFlow-Benchmark-Q4-Int8-Models;235
3DGAN;inference;CLX;fp32;Throughput;;0.00;benchmark_3DGAN_inference_aipg-ra-clx-88_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
A3C;inference;CLX;fp32;Latency;1;2.3609;benchmark_A3C_inference_aipg-ra-clx-88_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
A3C;inference;CLX;fp32;Throughput;1;870.25;benchmark_A3C_inference_aipg-ra-clx-88_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
DCGAN;inference;CLX;fp32;Throughput;;0.00;benchmark_DCGAN_inference_aipg-ra-clx-88_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
deepSpeech;inference;CLX;fp32;Throughput;1;0.00;benchmark_deepSpeech_inference_aipg-ra-clx-88_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
deepSpeech;inference;CLX;fp32;Latency;1;;benchmark_deepSpeech_inference_aipg-ra-clx-88_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
DRAW;inference;CLX;fp32;Latency;;;benchmark_DRAW_inference_aipg-ra-clx-88_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
DRAW;inference;CLX;fp32;Throughput;;0.00;benchmark_DRAW_inference_aipg-ra-clx-88_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
fastrcnn;training;CLX;fp32;Latency;1;363.497;benchmark_fastrcnn_training_aipg-ra-clx-88_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
fastrcnn;training;CLX;fp32;Throughput;1;2.75;benchmark_fastrcnn_training_aipg-ra-clx-88_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
fastrcnn;inference;CLX;fp32;Throughput;1;10.52;benchmark_fastrcnn_inference_aipg-ra-clx-88_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
fastrcnn;inference;CLX;fp32;Latency;1;0.190;benchmark_fastrcnn_inference_aipg-ra-clx-88_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
gnmt;inference;CLX;fp32;Throughput;32;29.94;benchmark_gnmt_inference_aipg-ra-clx-88_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
gnmt;inference;CLX;fp32;Latency;1;295.9733;benchmark_gnmt_inference_aipg-ra-clx-88_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
inception_resnet_v2;inference;CLX;fp32;Throughput;128;77.40;benchmark_inception_resnet_v2_inference_aipg-ra-clx-88_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
inception_resnet_v2;inference;CLX;fp32;Latency;1;62.7;benchmark_inception_resnet_v2_inference_aipg-ra-clx-88_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
inceptionv3;inference;CLX;fp32;Throughput;128;448.34;benchmark_inceptionv3_inference_aipg-ra-clx-88_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
inceptionv3;inference;CLX;fp32;Latency;1;10.692;benchmark_inceptionv3_inference_aipg-ra-clx-88_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
inception_v4;inference;CLX;fp32;Throughput;128;149.20;benchmark_inception_v4_inference_aipg-ra-clx-88_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
inception_v4;inference;CLX;fp32;Latency;1;30.2;benchmark_inception_v4_inference_aipg-ra-clx-88_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
mobilenet_v1;inference;CLX;fp32;Throughput;100;608.00;benchmark_mobilenet_v1_inference_aipg-ra-clx-88_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
mobilenet_v1;inference;CLX;fp32;Latency;1;5.9;benchmark_mobilenet_v1_inference_aipg-ra-clx-88_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
resnet50;inference;CLX;fp32;Throughput;128;650.38;benchmark_resnet50_inference_aipg-ra-clx-88_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
resnet50;inference;CLX;fp32;Latency;1;6.750;benchmark_resnet50_inference_aipg-ra-clx-88_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
rfcn;inference;CLX;fp32;Throughput;1;7.12;benchmark_rfcn_inference_aipg-ra-clx-88_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
rfcn;inference;CLX;fp32;Latency;1;281;benchmark_rfcn_inference_aipg-ra-clx-88_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
SqueezeNet;inference;CLX;fp32;Throughput;64;1682.60;benchmark_SqueezeNet_inference_aipg-ra-clx-88_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
SqueezeNet;inference;CLX;fp32;Latency;1;6.255;benchmark_SqueezeNet_inference_aipg-ra-clx-88_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
transformerLanguage;inference;CLX;fp32;Throughput;32;0.00;benchmark_transformerLanguage_inference_aipg-ra-clx-88_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
transformerLanguage;inference;CLX;fp32;Latency;1;;benchmark_transformerLanguage_inference_aipg-ra-clx-88_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
transformerSpeech;inference;CLX;fp32;Throughput;128;0.00;benchmark_transformerSpeech_inference_aipg-ra-clx-88_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
transformerSpeech;inference;CLX;fp32;Latency;1;;benchmark_transformerSpeech_inference_aipg-ra-clx-88_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
WaveNet;inference;CLX;fp32;Throughput;1;599.99;benchmark_WaveNet_inference_aipg-ra-clx-88_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
WaveNet;inference;CLX;fp32;Latency;1;3.333377;benchmark_WaveNet_inference_aipg-ra-clx-88_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
wideDeep;inference;CLX;fp32;Throughput;1024;84553.84;benchmark_wideDeep_inference_aipg-ra-clx-88_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
wideDeep;inference;CLX;fp32;Latency;1;1.16;benchmark_wideDeep_inference_aipg-ra-clx-88_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
WaveNet_Magenta;inference;CLX;fp32;Throughput;1;0.00;benchmark_WaveNet_Magenta_inference_aipg-ra-clx-88_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
WaveNet_Magenta;inference;CLX;fp32;Latency;1;;benchmark_WaveNet_Magenta_inference_aipg-ra-clx-88_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
UNet;inference;CLX;fp32;Latency;1;22.8464;benchmark_UNet_inference_aipg-ra-clx-88_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
UNet;inference;CLX;fp32;Throughput;1;78.78;benchmark_UNet_inference_aipg-ra-clx-88_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
YoloV2;inference;CLX;fp32;Throughput;8;80.00;benchmark_YoloV2_inference_aipg-ra-clx-88_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
YoloV2;inference;CLX;fp32;Latency;1;26.5;benchmark_YoloV2_inference_aipg-ra-clx-88_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
NCF;inference;CLX;fp32;Throughput;256;1220726.20;benchmark_NCF_inference_aipg-ra-clx-90_throughput.log;Private-TensorFlow-Benchmark-Q3-FP32-Models-CLX;312
NCF;inference;CLX;fp32;Latency;1;0.293;benchmark_NCF_inference_aipg-ra-clx-90_latency.log;Private-TensorFlow-Benchmark-Q3-FP32-Models-CLX;312
Wide_Deep_Census;training;CLX;fp32;Accuracy;40;1.01.0;benchmark_Wide_Deep_Census_training_aipg-ra-clx-90_throughput.log;Private-TensorFlow-Benchmark-Q3-FP32-Models-CLX;312
Wide_Deep_Census;training;CLX;fp32;Throughput;40;10020.9602955;benchmark_Wide_Deep_Census_training_aipg-ra-clx-90_throughput.log;Private-TensorFlow-Benchmark-Q3-FP32-Models-CLX;312
Wide_Deep_Criteo;training;CLX;fp32;Accuracy;128;;benchmark_Wide_Deep_Criteo_training_aipg-ra-clx-90_throughput.log;Private-TensorFlow-Benchmark-Q3-FP32-Models-CLX;312
Wide_Deep_Criteo;training;CLX;fp32;Throughput;128;;benchmark_Wide_Deep_Criteo_training_aipg-ra-clx-90_throughput.log;Private-TensorFlow-Benchmark-Q3-FP32-Models-CLX;312
MobileNet_v1;training;CLX;fp32;Throughput;64;189.4507;benchmark_MobileNet_v1_training_aipg-ra-clx-90_throughput.log;Private-TensorFlow-Benchmark-Q3-FP32-Models-CLX;312
Inception_ResNet_v2;training;CLX;fp32;Throughput;64;11.8954;benchmark_Inception_ResNet_v2_training_aipg-ra-clx-90_throughput.log;Private-TensorFlow-Benchmark-Q3-FP32-Models-CLX;312
faster_rcnn;inference;CLX;fp32;Accuracy;1;0.316,0.489,;faster_rcnn/benchmark_faster_rcnn_inference_fp32_accuracy_py2_aipg-ra-clx-91.log;Intel-Models-Benchmark-fp32-Trigger;296
faster_rcnn;inference;SKX;fp32;Accuracy;1;0.316,0.489,;faster_rcnn/benchmark_faster_rcnn_inference_fp32_accuracy_py2_aipg-ra-skx-54.log;Intel-Models-Benchmark-fp32-Trigger;296
faster_rcnn;inference;CLX;fp32;Latency;1;181;faster_rcnn/benchmark_faster_rcnn_inference_fp32_latency_py2_aipg-ra-clx-91.log;Intel-Models-Benchmark-fp32-Trigger;296
faster_rcnn;inference;CLX;fp32;Throughput;1;5.52;faster_rcnn/benchmark_faster_rcnn_inference_fp32_latency_py2_aipg-ra-clx-91.log;Intel-Models-Benchmark-fp32-Trigger;296
faster_rcnn;inference;SKX;fp32;Latency;1;193;faster_rcnn/benchmark_faster_rcnn_inference_fp32_latency_py2_aipg-ra-skx-54.log;Intel-Models-Benchmark-fp32-Trigger;296
faster_rcnn;inference;SKX;fp32;Throughput;1;5.18;faster_rcnn/benchmark_faster_rcnn_inference_fp32_latency_py2_aipg-ra-skx-54.log;Intel-Models-Benchmark-fp32-Trigger;296
inceptionv3;inference;CLX;fp32;Accuracy;100;0.7676,0.9341;inceptionv3/benchmark_inceptionv3_inference_fp32_accuracy_py2_aipg-ra-clx-89.log;Intel-Models-Benchmark-fp32-Trigger;296
inceptionv3;inference;SKX;fp32;Accuracy;100;0.7676,0.9341;inceptionv3/benchmark_inceptionv3_inference_fp32_accuracy_py2_aipg-ra-skx-52.log;Intel-Models-Benchmark-fp32-Trigger;296
inceptionv3;inference;CLX;fp32;Latency;1;12.082;inceptionv3/benchmark_inceptionv3_inference_fp32_latency_py2_aipg-ra-clx-89.log;Intel-Models-Benchmark-fp32-Trigger;296
inceptionv3;inference;SKX;fp32;Latency;1;12.528;inceptionv3/benchmark_inceptionv3_inference_fp32_latency_py2_aipg-ra-skx-52.log;Intel-Models-Benchmark-fp32-Trigger;296
inceptionv3;inference;CLX;fp32;Throughput;128;211.705;inceptionv3/benchmark_inceptionv3_inference_fp32_throughput_py2_aipg-ra-clx-89.log;Intel-Models-Benchmark-fp32-Trigger;296
inceptionv3;inference;SKX;fp32;Throughput;128;209.606;inceptionv3/benchmark_inceptionv3_inference_fp32_throughput_py2_aipg-ra-skx-52.log;Intel-Models-Benchmark-fp32-Trigger;296
inceptionv4;inference;SKX;fp32;Accuracy;100;;inceptionv4/benchmark_inceptionv4_inference_fp32_accuracy_py2_aipg-ra-skx-53.log;Intel-Models-Benchmark-fp32-Trigger;296
inceptionv4;inference;CLX;fp32;Accuracy;100;0.8018,0.9519;inceptionv4/benchmark_inceptionv4_inference_fp32_accuracy_py2_aipg-ra-clx-109.log;Intel-Models-Benchmark-fp32-Trigger;296
inceptionv4;inference;SKX;fp32;Latency;1;;inceptionv4/benchmark_inceptionv4_inference_fp32_latency_py2_aipg-ra-skx-53.log;Intel-Models-Benchmark-fp32-Trigger;296
inceptionv4;inference;CLX;fp32;Latency;1;20.577;inceptionv4/benchmark_inceptionv4_inference_fp32_latency_py2_aipg-ra-clx-109.log;Intel-Models-Benchmark-fp32-Trigger;296
inceptionv4;inference;CLX;fp32;Throughput;240;101.479741109;inceptionv4/benchmark_inceptionv4_inference_fp32_throughput_py2_aipg-ra-clx-109.log;Intel-Models-Benchmark-fp32-Trigger;296
inceptionv4;inference;SKX;fp32;Throughput;240;;inceptionv4/benchmark_inceptionv4_inference_fp32_throughput_py2_aipg-ra-skx-53.log;Intel-Models-Benchmark-fp32-Trigger;296
inception_resnet_v2;inference;SKX;fp32;Accuracy;100;0.8037,0.9525;inception_resnet_v2/benchmark_inception_resnet_v2_inference_fp32_accuracy_py2_aipg-ra-skx-52.log;Intel-Models-Benchmark-fp32-Trigger;296
inception_resnet_v2;inference;CLX;fp32;Accuracy;100;0.8037,0.9525;inception_resnet_v2/benchmark_inception_resnet_v2_inference_fp32_accuracy_py2_aipg-ra-clx-92.log;Intel-Models-Benchmark-fp32-Trigger;296
inception_resnet_v2;inference;CLX;fp32;Latency;1;41.270;inception_resnet_v2/benchmark_inception_resnet_v2_inference_fp32_latency_py2_aipg-ra-clx-92.log;Intel-Models-Benchmark-fp32-Trigger;296
inception_resnet_v2;inference;SKX;fp32;Latency;1;42.648;inception_resnet_v2/benchmark_inception_resnet_v2_inference_fp32_latency_py2_aipg-ra-skx-52.log;Intel-Models-Benchmark-fp32-Trigger;296
inception_resnet_v2;inference;SKX;fp32;Throughput;128;75.017;inception_resnet_v2/benchmark_inception_resnet_v2_inference_fp32_throughput_py2_aipg-ra-skx-52.log;Intel-Models-Benchmark-fp32-Trigger;296
inception_resnet_v2;inference;CLX;fp32;Throughput;128;77.708;inception_resnet_v2/benchmark_inception_resnet_v2_inference_fp32_throughput_py2_aipg-ra-clx-92.log;Intel-Models-Benchmark-fp32-Trigger;296
mobilenet_v1;inference;CLX;fp32;Accuracy;100;0.7102,0.8999;mobilenet_v1/benchmark_mobilenet_v1_inference_fp32_accuracy_py2_aipg-ra-clx-104.log;Intel-Models-Benchmark-fp32-Trigger;296
mobilenet_v1;inference;SKX;fp32;Accuracy;100;0.7102,0.8999;mobilenet_v1/benchmark_mobilenet_v1_inference_fp32_accuracy_py2_aipg-ra-skx-52.log;Intel-Models-Benchmark-fp32-Trigger;296
mobilenet_v1;inference;CLX;fp32;Latency;1;5.8;mobilenet_v1/benchmark_mobilenet_v1_inference_fp32_latency_py2_aipg-ra-clx-104.log;Intel-Models-Benchmark-fp32-Trigger;296
mobilenet_v1;inference;SKX;fp32;Latency;1;6.2;mobilenet_v1/benchmark_mobilenet_v1_inference_fp32_latency_py2_aipg-ra-skx-52.log;Intel-Models-Benchmark-fp32-Trigger;296
mobilenet_v1;inference;SKX;fp32;Throughput;256;290.0;mobilenet_v1/benchmark_mobilenet_v1_inference_fp32_throughput_py2_aipg-ra-skx-52.log;Intel-Models-Benchmark-fp32-Trigger;296
mobilenet_v1;inference;CLX;fp32;Throughput;256;302.1;mobilenet_v1/benchmark_mobilenet_v1_inference_fp32_throughput_py2_aipg-ra-clx-104.log;Intel-Models-Benchmark-fp32-Trigger;296
ncf;inference;SKX;fp32;Accuracy;256;;ncf/benchmark_ncf_inference_fp32_accuracy_py2_aipg-ra-skx-54.log;Intel-Models-Benchmark-fp32-Trigger;296
ncf;inference;CLX;fp32;Accuracy;256;;ncf/benchmark_ncf_inference_fp32_accuracy_py2_aipg-ra-clx-104.log;Intel-Models-Benchmark-fp32-Trigger;296
ncf;inference;CLX;fp32;Latency;1;0.391;ncf/benchmark_ncf_inference_fp32_latency_py2_aipg-ra-clx-104.log;Intel-Models-Benchmark-fp32-Trigger;296
ncf;inference;SKX;fp32;Latency;1;0.396;ncf/benchmark_ncf_inference_fp32_latency_py2_aipg-ra-skx-54.log;Intel-Models-Benchmark-fp32-Trigger;296
ncf;inference;CLX;fp32;Throughput;256;554362.6;ncf/benchmark_ncf_inference_fp32_throughput_py2_aipg-ra-clx-104.log;Intel-Models-Benchmark-fp32-Trigger;296
ncf;inference;SKX;fp32;Throughput;256;501356.8;ncf/benchmark_ncf_inference_fp32_throughput_py2_aipg-ra-skx-54.log;Intel-Models-Benchmark-fp32-Trigger;296
resnet101;inference;CLX;fp32;Accuracy;100;0.7640,0.9288;resnet101/benchmark_resnet101_inference_fp32_accuracy_py2_aipg-ra-clx-91.log;Intel-Models-Benchmark-fp32-Trigger;296
resnet101;inference;SKX;fp32;Accuracy;100;0.7640,0.9288;resnet101/benchmark_resnet101_inference_fp32_accuracy_py2_aipg-ra-skx-52.log;Intel-Models-Benchmark-fp32-Trigger;296
resnet101;inference;SKX;fp32;Latency;1;15.970;resnet101/benchmark_resnet101_inference_fp32_latency_py2_aipg-ra-skx-52.log;Intel-Models-Benchmark-fp32-Trigger;296
resnet101;inference;CLX;fp32;Latency;1;15.315;resnet101/benchmark_resnet101_inference_fp32_latency_py2_aipg-ra-clx-91.log;Intel-Models-Benchmark-fp32-Trigger;296
resnet101;inference;CLX;fp32;Throughput;128;155.399;resnet101/benchmark_resnet101_inference_fp32_throughput_py2_aipg-ra-clx-91.log;Intel-Models-Benchmark-fp32-Trigger;296
resnet101;inference;SKX;fp32;Throughput;128;147.062;resnet101/benchmark_resnet101_inference_fp32_throughput_py2_aipg-ra-skx-52.log;Intel-Models-Benchmark-fp32-Trigger;296
resnet50;inference;SKX;fp32;Accuracy;100;0.7429,0.9188;resnet50/benchmark_resnet50_inference_fp32_accuracy_py2_aipg-ra-skx-52.log;Intel-Models-Benchmark-fp32-Trigger;296
resnet50;inference;CLX;fp32;Accuracy;100;0.7429,0.9188;resnet50/benchmark_resnet50_inference_fp32_accuracy_py2_aipg-ra-clx-89.log;Intel-Models-Benchmark-fp32-Trigger;296
resnet50;inference;SKX;fp32;Latency;1;8.556;resnet50/benchmark_resnet50_inference_fp32_latency_py2_aipg-ra-skx-52.log;Intel-Models-Benchmark-fp32-Trigger;296
resnet50;inference;CLX;fp32;Latency;1;8.104;resnet50/benchmark_resnet50_inference_fp32_latency_py2_aipg-ra-clx-89.log;Intel-Models-Benchmark-fp32-Trigger;296
resnet50;inference;CLX;fp32;Throughput;128;309.636;resnet50/benchmark_resnet50_inference_fp32_throughput_py2_aipg-ra-clx-89.log;Intel-Models-Benchmark-fp32-Trigger;296
resnet50;inference;SKX;fp32;Throughput;128;303.782;resnet50/benchmark_resnet50_inference_fp32_throughput_py2_aipg-ra-skx-52.log;Intel-Models-Benchmark-fp32-Trigger;296
resnet50v1_5;inference;SKX;fp32;Accuracy;100;0.7651,0.9307;resnet50v1_5/benchmark_resnet50v1_5_inference_fp32_accuracy_py2_aipg-ra-skx-52.log;Intel-Models-Benchmark-fp32-Trigger;296
resnet50v1_5;inference;CLX;fp32;Accuracy;100;0.7651,0.9307;resnet50v1_5/benchmark_resnet50v1_5_inference_fp32_accuracy_py2_aipg-ra-clx-109.log;Intel-Models-Benchmark-fp32-Trigger;296
resnet50v1_5;inference;SKX;fp32;Latency;1;9.984;resnet50v1_5/benchmark_resnet50v1_5_inference_fp32_latency_py2_aipg-ra-skx-52.log;Intel-Models-Benchmark-fp32-Trigger;296
resnet50v1_5;inference;CLX;fp32;Latency;1;9.503;resnet50v1_5/benchmark_resnet50v1_5_inference_fp32_latency_py2_aipg-ra-clx-109.log;Intel-Models-Benchmark-fp32-Trigger;296
resnet50v1_5;inference;CLX;fp32;Throughput;128;239.130;resnet50v1_5/benchmark_resnet50v1_5_inference_fp32_throughput_py2_aipg-ra-clx-109.log;Intel-Models-Benchmark-fp32-Trigger;296
resnet50v1_5;inference;SKX;fp32;Throughput;128;231.074;resnet50v1_5/benchmark_resnet50v1_5_inference_fp32_throughput_py2_aipg-ra-skx-52.log;Intel-Models-Benchmark-fp32-Trigger;296
rfcn;inference;SKX;fp32;Accuracy;1;;rfcn/benchmark_rfcn_inference_fp32_accuracy_py2_aipg-ra-skx-53.log;Intel-Models-Benchmark-fp32-Trigger;296
rfcn;inference;CLX;fp32;Accuracy;1;0.347,0.532,;rfcn/benchmark_rfcn_inference_fp32_accuracy_py2_aipg-ra-clx-106.log;Intel-Models-Benchmark-fp32-Trigger;296
rfcn;inference;SKX;fp32;Latency;1;;rfcn/benchmark_rfcn_inference_fp32_latency_py2_aipg-ra-skx-53.log;Intel-Models-Benchmark-fp32-Trigger;296
rfcn;inference;CLX;fp32;Latency;1;0;rfcn/benchmark_rfcn_inference_fp32_latency_py2_aipg-ra-clx-106.log;Intel-Models-Benchmark-fp32-Trigger;296
ssd-mobilenet;inference;CLX;fp32;Accuracy;1;0.231,0.349,;ssd-mobilenet/benchmark_ssd-mobilenet_inference_fp32_accuracy_py2_aipg-ra-clx-91.log;Intel-Models-Benchmark-fp32-Trigger;296
ssd-mobilenet;inference;SKX;fp32;Accuracy;1;0.231,0.349,;ssd-mobilenet/benchmark_ssd-mobilenet_inference_fp32_accuracy_py2_aipg-ra-skx-52.log;Intel-Models-Benchmark-fp32-Trigger;296
ssd-mobilenet;inference;SKX;fp32;Latency;1;27.8;ssd-mobilenet/benchmark_ssd-mobilenet_inference_fp32_throughput_py2_aipg-ra-skx-52.log;Intel-Models-Benchmark-fp32-Trigger;296
ssd-mobilenet;inference;SKX;fp32;Throughput;1;35.97;ssd-mobilenet/benchmark_ssd-mobilenet_inference_fp32_throughput_py2_aipg-ra-skx-52.log;Intel-Models-Benchmark-fp32-Trigger;296
ssd-mobilenet;inference;CLX;fp32;Latency;1;26.1;ssd-mobilenet/benchmark_ssd-mobilenet_inference_fp32_throughput_py2_aipg-ra-clx-91.log;Intel-Models-Benchmark-fp32-Trigger;296
ssd-mobilenet;inference;CLX;fp32;Throughput;1;38.31;ssd-mobilenet/benchmark_ssd-mobilenet_inference_fp32_throughput_py2_aipg-ra-clx-91.log;Intel-Models-Benchmark-fp32-Trigger;296
transformer_language;inference;SKX;fp32;Latency;1;;transformer_language/benchmark_transformer_language_inference_fp32_latency_py2_aipg-ra-skx-52.log;Intel-Models-Benchmark-fp32-Trigger;296
transformer_language;inference;CLX;fp32;Latency;1;;transformer_language/benchmark_transformer_language_inference_fp32_latency_py2_aipg-ra-clx-107.log;Intel-Models-Benchmark-fp32-Trigger;296
transformer_language;inference;CLX;fp32;Throughput;32;;transformer_language/benchmark_transformer_language_inference_fp32_throughput_py2_aipg-ra-clx-107.log;Intel-Models-Benchmark-fp32-Trigger;296
transformer_language;inference;SKX;fp32;Throughput;32;;transformer_language/benchmark_transformer_language_inference_fp32_throughput_py2_aipg-ra-skx-52.log;Intel-Models-Benchmark-fp32-Trigger;296
wide_deep;inference;CLX;fp32;Latency;1;1.16;wide_deep/benchmark_wide_deep_inference_fp32_latency_py2_aipg-ra-clx-109.log;Intel-Models-Benchmark-fp32-Trigger;296
wide_deep;inference;SKX;fp32;Latency;1;0.00;wide_deep/benchmark_wide_deep_inference_fp32_latency_py2_aipg-ra-skx-53.log;Intel-Models-Benchmark-fp32-Trigger;296
wide_deep;inference;SKX;fp32;Throughput;1024;;wide_deep/benchmark_wide_deep_inference_fp32_throughput_py2_aipg-ra-skx-53.log;Intel-Models-Benchmark-fp32-Trigger;296
wide_deep;inference;CLX;fp32;Throughput;1024;4016.7420914;wide_deep/benchmark_wide_deep_inference_fp32_throughput_py2_aipg-ra-clx-109.log;Intel-Models-Benchmark-fp32-Trigger;296
NCF;inference;SKX;fp32;Throughput;256;1366558.40;benchmark_NCF_inference_aipg-ra-skx-52_throughput.log;Private-TensorFlow-Benchmark-Q3-FP32-Models;323
NCF;inference;SKX;fp32;Latency;1;0.291;benchmark_NCF_inference_aipg-ra-skx-52_latency.log;Private-TensorFlow-Benchmark-Q3-FP32-Models;323
Wide_Deep_Census;training;SKX;fp32;Accuracy;40;1.01.0;benchmark_Wide_Deep_Census_training_aipg-ra-skx-52_throughput.log;Private-TensorFlow-Benchmark-Q3-FP32-Models;323
Wide_Deep_Census;training;SKX;fp32;Throughput;40;9785.461555;benchmark_Wide_Deep_Census_training_aipg-ra-skx-52_throughput.log;Private-TensorFlow-Benchmark-Q3-FP32-Models;323
Wide_Deep_Criteo;training;SKX;fp32;Accuracy;128;;benchmark_Wide_Deep_Criteo_training_aipg-ra-skx-52_throughput.log;Private-TensorFlow-Benchmark-Q3-FP32-Models;323
Wide_Deep_Criteo;training;SKX;fp32;Throughput;128;;benchmark_Wide_Deep_Criteo_training_aipg-ra-skx-52_throughput.log;Private-TensorFlow-Benchmark-Q3-FP32-Models;323
MobileNet_v1;training;SKX;fp32;Throughput;64;183.9237;benchmark_MobileNet_v1_training_aipg-ra-skx-52_throughput.log;Private-TensorFlow-Benchmark-Q3-FP32-Models;323
Inception_ResNet_v2;training;SKX;fp32;Throughput;64;11.3403;benchmark_Inception_ResNet_v2_training_aipg-ra-skx-52_throughput.log;Private-TensorFlow-Benchmark-Q3-FP32-Models;323
inception_resnet_v2;inference;CLX;int8;Accuracy;100;0.8014,0.9520;inception_resnet_v2/benchmark_inception_resnet_v2_inference_int8_accuracy_py2_aipg-ra-clx-92.log;Intel-Models-Benchmark-int8-Trigger;79
inception_resnet_v2;inference;SKX;int8;Accuracy;100;0.8019,0.9520;inception_resnet_v2/benchmark_inception_resnet_v2_inference_int8_accuracy_py2_aipg-ra-skx-54.log;Intel-Models-Benchmark-int8-Trigger;79
inception_resnet_v2;inference;SKX;int8;Latency;1;41.827;inception_resnet_v2/benchmark_inception_resnet_v2_inference_int8_latency_py2_aipg-ra-skx-54.log;Intel-Models-Benchmark-int8-Trigger;79
inception_resnet_v2;inference;CLX;int8;Latency;1;36.950;inception_resnet_v2/benchmark_inception_resnet_v2_inference_int8_latency_py2_aipg-ra-clx-92.log;Intel-Models-Benchmark-int8-Trigger;79
inception_resnet_v2;inference;CLX;int8;Throughput;128;267.821;inception_resnet_v2/benchmark_inception_resnet_v2_inference_int8_throughput_py2_aipg-ra-clx-92.log;Intel-Models-Benchmark-int8-Trigger;79
inception_resnet_v2;inference;SKX;int8;Throughput;128;146.118;inception_resnet_v2/benchmark_inception_resnet_v2_inference_int8_throughput_py2_aipg-ra-skx-54.log;Intel-Models-Benchmark-int8-Trigger;79
inceptionv3;inference;CLX;int8;Accuracy;100;0.7651,0.9335;inceptionv3/benchmark_inceptionv3_inference_int8_accuracy_py2_aipg-ra-clx-92.log;Intel-Models-Benchmark-int8-Trigger;79
inceptionv3;inference;SKX;int8;Accuracy;100;;inceptionv3/benchmark_inceptionv3_inference_int8_accuracy_py2_aipg-ra-skx-53.log;Intel-Models-Benchmark-int8-Trigger;79
inceptionv3;inference;SKX;int8;Latency;1;;inceptionv3/benchmark_inceptionv3_inference_int8_latency_py2_aipg-ra-skx-53.log;Intel-Models-Benchmark-int8-Trigger;79
inceptionv3;inference;CLX;int8;Latency;1;6.212;inceptionv3/benchmark_inceptionv3_inference_int8_latency_py2_aipg-ra-clx-92.log;Intel-Models-Benchmark-int8-Trigger;79
inceptionv3;inference;SKX;int8;Throughput;128;;inceptionv3/benchmark_inceptionv3_inference_int8_throughput_py2_aipg-ra-skx-53.log;Intel-Models-Benchmark-int8-Trigger;79
inceptionv3;inference;CLX;int8;Throughput;128;687.236991201;inceptionv3/benchmark_inceptionv3_inference_int8_throughput_py2_aipg-ra-clx-92.log;Intel-Models-Benchmark-int8-Trigger;79
inceptionv4;inference;CLX;int8;Accuracy;100;0.7986,0.9503;inceptionv4/benchmark_inceptionv4_inference_int8_accuracy_py2_aipg-ra-clx-89.log;Intel-Models-Benchmark-int8-Trigger;79
inceptionv4;inference;SKX;int8;Accuracy;100;;inceptionv4/benchmark_inceptionv4_inference_int8_accuracy_py2_aipg-ra-skx-53.log;Intel-Models-Benchmark-int8-Trigger;79
inceptionv4;inference;SKX;int8;Latency;1;;inceptionv4/benchmark_inceptionv4_inference_int8_latency_py2_aipg-ra-skx-53.log;Intel-Models-Benchmark-int8-Trigger;79
inceptionv4;inference;CLX;int8;Latency;1;18.011;inceptionv4/benchmark_inceptionv4_inference_int8_latency_py2_aipg-ra-clx-89.log;Intel-Models-Benchmark-int8-Trigger;79
inceptionv4;inference;CLX;int8;Throughput;240;343.944475936;inceptionv4/benchmark_inceptionv4_inference_int8_throughput_py2_aipg-ra-clx-89.log;Intel-Models-Benchmark-int8-Trigger;79
inceptionv4;inference;SKX;int8;Throughput;240;;inceptionv4/benchmark_inceptionv4_inference_int8_throughput_py2_aipg-ra-skx-53.log;Intel-Models-Benchmark-int8-Trigger;79
resnet101;inference;SKX;int8;Accuracy;100;0.7573,0.9262;resnet101/benchmark_resnet101_inference_int8_accuracy_py2_aipg-ra-skx-52.log;Intel-Models-Benchmark-int8-Trigger;79
resnet101;inference;CLX;int8;Accuracy;100;0.7579,0.9260;resnet101/benchmark_resnet101_inference_int8_accuracy_py2_aipg-ra-clx-106.log;Intel-Models-Benchmark-int8-Trigger;79
resnet101;inference;SKX;int8;Latency;1;13.669;resnet101/benchmark_resnet101_inference_int8_latency_py2_aipg-ra-skx-52.log;Intel-Models-Benchmark-int8-Trigger;79
resnet101;inference;CLX;int8;Latency;1;11.105;resnet101/benchmark_resnet101_inference_int8_latency_py2_aipg-ra-clx-106.log;Intel-Models-Benchmark-int8-Trigger;79
resnet101;inference;CLX;int8;Throughput;128;589.252;resnet101/benchmark_resnet101_inference_int8_throughput_py2_aipg-ra-clx-106.log;Intel-Models-Benchmark-int8-Trigger;79
resnet101;inference;SKX;int8;Throughput;128;301.829;resnet101/benchmark_resnet101_inference_int8_throughput_py2_aipg-ra-skx-52.log;Intel-Models-Benchmark-int8-Trigger;79
resnet50;inference;SKX;int8;Accuracy;100;0.7379,0.9164;resnet50/benchmark_resnet50_inference_int8_accuracy_py2_aipg-ra-skx-52.log;Intel-Models-Benchmark-int8-Trigger;79
resnet50;inference;CLX;int8;Accuracy;100;0.7379,0.9164;resnet50/benchmark_resnet50_inference_int8_accuracy_py2_aipg-ra-clx-92.log;Intel-Models-Benchmark-int8-Trigger;79
resnet50;inference;SKX;int8;Latency;1;5.548;resnet50/benchmark_resnet50_inference_int8_latency_py2_aipg-ra-skx-52.log;Intel-Models-Benchmark-int8-Trigger;79
resnet50;inference;CLX;int8;Latency;1;4.270;resnet50/benchmark_resnet50_inference_int8_latency_py2_aipg-ra-clx-92.log;Intel-Models-Benchmark-int8-Trigger;79
resnet50;inference;SKX;int8;Throughput;128;504.350;resnet50/benchmark_resnet50_inference_int8_throughput_py2_aipg-ra-skx-52.log;Intel-Models-Benchmark-int8-Trigger;79
resnet50;inference;CLX;int8;Throughput;128;895.306;resnet50/benchmark_resnet50_inference_int8_throughput_py2_aipg-ra-clx-92.log;Intel-Models-Benchmark-int8-Trigger;79
resnet50v1_5;inference;CLX;int8;Accuracy;100;0.7621,0.9297;resnet50v1_5/benchmark_resnet50v1_5_inference_int8_accuracy_py2_aipg-ra-clx-106.log;Intel-Models-Benchmark-int8-Trigger;79
resnet50v1_5;inference;SKX;int8;Accuracy;100;0.7622,0.9298;resnet50v1_5/benchmark_resnet50v1_5_inference_int8_accuracy_py2_aipg-ra-skx-54.log;Intel-Models-Benchmark-int8-Trigger;79
resnet50v1_5;inference;CLX;int8;Latency;1;9.277;resnet50v1_5/benchmark_resnet50v1_5_inference_int8_latency_py2_aipg-ra-clx-106.log;Intel-Models-Benchmark-int8-Trigger;79
resnet50v1_5;inference;SKX;int8;Latency;1;11.265;resnet50v1_5/benchmark_resnet50v1_5_inference_int8_latency_py2_aipg-ra-skx-54.log;Intel-Models-Benchmark-int8-Trigger;79
resnet50v1_5;inference;SKX;int8;Throughput;128;432.122;resnet50v1_5/benchmark_resnet50v1_5_inference_int8_throughput_py2_aipg-ra-skx-54.log;Intel-Models-Benchmark-int8-Trigger;79
resnet50v1_5;inference;CLX;int8;Throughput;128;737.796;resnet50v1_5/benchmark_resnet50v1_5_inference_int8_throughput_py2_aipg-ra-clx-106.log;Intel-Models-Benchmark-int8-Trigger;79
rfcn;inference;CLX;int8;Accuracy;1;0.327,0.505,;rfcn/benchmark_rfcn_inference_int8_accuracy_py2_aipg-ra-clx-107.log;Intel-Models-Benchmark-int8-Trigger;79
rfcn;inference;SKX;int8;Accuracy;1;;rfcn/benchmark_rfcn_inference_int8_accuracy_py2_aipg-ra-skx-53.log;Intel-Models-Benchmark-int8-Trigger;79
rfcn;inference;CLX;int8;Latency;1;0;rfcn/benchmark_rfcn_inference_int8_latency_py2_aipg-ra-clx-107.log;Intel-Models-Benchmark-int8-Trigger;79
rfcn;inference;SKX;int8;Latency;1;;rfcn/benchmark_rfcn_inference_int8_latency_py2_aipg-ra-skx-53.log;Intel-Models-Benchmark-int8-Trigger;79
ssd-mobilenet;inference;SKX;int8;Accuracy;1;0.188,0.288,;ssd-mobilenet/benchmark_ssd-mobilenet_inference_int8_accuracy_py2_aipg-ra-skx-52.log;Intel-Models-Benchmark-int8-Trigger;79
ssd-mobilenet;inference;CLX;int8;Accuracy;1;0.219,0.331,;ssd-mobilenet/benchmark_ssd-mobilenet_inference_int8_accuracy_py2_aipg-ra-clx-105.log;Intel-Models-Benchmark-int8-Trigger;79
ssd-mobilenet;inference;CLX;int8;Latency;1;18.23;ssd-mobilenet/benchmark_ssd-mobilenet_inference_int8_throughput_py2_aipg-ra-clx-105.log;Intel-Models-Benchmark-int8-Trigger;79
ssd-mobilenet;inference;CLX;int8;Throughput;1;54.85;ssd-mobilenet/benchmark_ssd-mobilenet_inference_int8_throughput_py2_aipg-ra-clx-105.log;Intel-Models-Benchmark-int8-Trigger;79
ssd-mobilenet;inference;SKX;int8;Latency;1;18.23;ssd-mobilenet/benchmark_ssd-mobilenet_inference_int8_throughput_py2_aipg-ra-skx-52.log;Intel-Models-Benchmark-int8-Trigger;79
ssd-mobilenet;inference;SKX;int8;Throughput;1;54.85;ssd-mobilenet/benchmark_ssd-mobilenet_inference_int8_throughput_py2_aipg-ra-skx-52.log;Intel-Models-Benchmark-int8-Trigger;79
faster_rcnn;inference;SKX;int8;Accuracy;1;;faster_rcnn/benchmark_faster_rcnn_inference_int8_accuracy_py2_aipg-ra-skx-53.log;Intel-Models-Benchmark-int8-Trigger;79
faster_rcnn;inference;CLX;int8;Accuracy;1;0.309,0.477,;faster_rcnn/benchmark_faster_rcnn_inference_int8_accuracy_py2_aipg-ra-clx-105.log;Intel-Models-Benchmark-int8-Trigger;79
faster_rcnn;inference;CLX;int8;Latency;1;57.242;faster_rcnn/benchmark_faster_rcnn_inference_int8_latency_py2_aipg-ra-clx-105.log;Intel-Models-Benchmark-int8-Trigger;79
faster_rcnn;inference;CLX;int8;Throughput;1;17.47;faster_rcnn/benchmark_faster_rcnn_inference_int8_latency_py2_aipg-ra-clx-105.log;Intel-Models-Benchmark-int8-Trigger;79
faster_rcnn;inference;SKX;int8;Latency;1;;faster_rcnn/benchmark_faster_rcnn_inference_int8_latency_py2_aipg-ra-skx-53.log;Intel-Models-Benchmark-int8-Trigger;79
faster_rcnn;inference;SKX;int8;Throughput;1;;faster_rcnn/benchmark_faster_rcnn_inference_int8_latency_py2_aipg-ra-skx-53.log;Intel-Models-Benchmark-int8-Trigger;79
DenseNet;inference;SKX;fp32;Throughput;128;739.78;Q2_models_DenseNet_throughput.log;Private-TensorFlow-Benchmark-Q2-Py3-Master;453
DenseNet;inference;SKX;fp32;Latency;1;14.704466;Q2_models_DenseNet_latency.log;Private-TensorFlow-Benchmark-Q2-Py3-Master;453
3DUNet;inference;SKX;fp32;Throughput;1;;Q2_models_3DUNet_throughput.log;Private-TensorFlow-Benchmark-Q2-Py3-Master;453
3DUNet;inference;SKX;fp32;Latency;1;;Q2_models_3DUNet_latency.log;Private-TensorFlow-Benchmark-Q2-Py3-Master;453
MaskRCNN;inference;SKX;fp32;Throughput;1;3.18;Q2_models_MaskRCNN_throughput.log;Private-TensorFlow-Benchmark-Q2-Py3-Master;453
MaskRCNN;inference;SKX;fp32;Latency;1;622.5189;Q2_models_MaskRCNN_latency.log;Private-TensorFlow-Benchmark-Q2-Py3-Master;453
ResNet101;inference;CLX;int8;Throughput;128;614.231137048;benchmark_ResNet101_inference_aipg-ra-clx-89_throughput.log;Private-TensorFlow-Benchmark-Q4-Int8-Models-CLX;224
ResNet101;inference;CLX;int8;Latency;1;11.151;benchmark_ResNet101_inference_aipg-ra-clx-89_latency.log;Private-TensorFlow-Benchmark-Q4-Int8-Models-CLX;224
ResNet101;inference;CLX;int8;Accuracy;1;0.7578, 0.9260;benchmark_ResNet101_inference_aipg-ra-clx-89_accuracy.log;Private-TensorFlow-Benchmark-Q4-Int8-Models-CLX;224
InceptionV4;inference;CLX;int8;Throughput;240;336.989668689;benchmark_InceptionV4_inference_aipg-ra-clx-89_throughput.log;Private-TensorFlow-Benchmark-Q4-Int8-Models-CLX;224
InceptionV4;inference;CLX;int8;Latency;1;19.946;benchmark_InceptionV4_inference_aipg-ra-clx-89_latency.log;Private-TensorFlow-Benchmark-Q4-Int8-Models-CLX;224
InceptionV4;inference;CLX;int8;Accuracy;1;0.7988, 0.9504;benchmark_InceptionV4_inference_aipg-ra-clx-89_accuracy.log;Private-TensorFlow-Benchmark-Q4-Int8-Models-CLX;224
3DGAN;inference;SKX;fp32;Throughput;;0.00;benchmark_3DGAN_inference_aipg-ra-skx-53_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master;471
A3C;inference;SKX;fp32;Latency;1;2.3342;benchmark_A3C_inference_aipg-ra-skx-53_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master;471
A3C;inference;SKX;fp32;Throughput;1;887.38;benchmark_A3C_inference_aipg-ra-skx-53_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master;471
DCGAN;inference;SKX;fp32;Throughput;;0.00;benchmark_DCGAN_inference_aipg-ra-skx-53_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master;471
deepSpeech;inference;SKX;fp32;Throughput;1;0.00;benchmark_deepSpeech_inference_aipg-ra-skx-53_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master;471
deepSpeech;inference;SKX;fp32;Latency;1;;benchmark_deepSpeech_inference_aipg-ra-skx-53_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master;471
DRAW;inference;SKX;fp32;Latency;;;benchmark_DRAW_inference_aipg-ra-skx-53_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master;471
DRAW;inference;SKX;fp32;Throughput;;0.00;benchmark_DRAW_inference_aipg-ra-skx-53_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master;471
fastrcnn;training;SKX;fp32;Latency;1;;benchmark_fastrcnn_training_aipg-ra-skx-53_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master;471
fastrcnn;training;SKX;fp32;Throughput;1;;benchmark_fastrcnn_training_aipg-ra-skx-53_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master;471
fastrcnn;inference;SKX;fp32;Throughput;1;0.00;benchmark_fastrcnn_inference_aipg-ra-skx-53_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master;471
fastrcnn;inference;SKX;fp32;Latency;1;;benchmark_fastrcnn_inference_aipg-ra-skx-53_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master;471
gnmt;inference;SKX;fp32;Throughput;32;26.63;benchmark_gnmt_inference_aipg-ra-skx-53_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master;471
gnmt;inference;SKX;fp32;Latency;1;324.6147;benchmark_gnmt_inference_aipg-ra-skx-53_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master;471
inception_resnet_v2;inference;SKX;fp32;Throughput;128;72.60;benchmark_inception_resnet_v2_inference_aipg-ra-skx-53_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master;471
inception_resnet_v2;inference;SKX;fp32;Latency;1;64.7;benchmark_inception_resnet_v2_inference_aipg-ra-skx-53_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master;471
inceptionv3;inference;SKX;fp32;Throughput;128;443.19;benchmark_inceptionv3_inference_aipg-ra-skx-53_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master;471
inceptionv3;inference;SKX;fp32;Latency;1;11.150;benchmark_inceptionv3_inference_aipg-ra-skx-53_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master;471
inception_v4;inference;SKX;fp32;Throughput;128;144.60;benchmark_inception_v4_inference_aipg-ra-skx-53_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master;471
inception_v4;inference;SKX;fp32;Latency;1;33.0;benchmark_inception_v4_inference_aipg-ra-skx-53_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master;471
mobilenet_v1;inference;SKX;fp32;Throughput;100;583.60;benchmark_mobilenet_v1_inference_aipg-ra-skx-53_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master;471
mobilenet_v1;inference;SKX;fp32;Latency;1;6.2;benchmark_mobilenet_v1_inference_aipg-ra-skx-53_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master;471
resnet50;inference;SKX;fp32;Throughput;128;635.70;benchmark_resnet50_inference_aipg-ra-skx-53_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master;471
resnet50;inference;SKX;fp32;Latency;1;7.059;benchmark_resnet50_inference_aipg-ra-skx-53_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master;471
rfcn;inference;SKX;fp32;Throughput;1;6.76;benchmark_rfcn_inference_aipg-ra-skx-53_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master;471
rfcn;inference;SKX;fp32;Latency;1;296;benchmark_rfcn_inference_aipg-ra-skx-53_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master;471
SqueezeNet;inference;SKX;fp32;Throughput;64;1590.40;benchmark_SqueezeNet_inference_aipg-ra-skx-53_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master;471
SqueezeNet;inference;SKX;fp32;Latency;1;6.46;benchmark_SqueezeNet_inference_aipg-ra-skx-53_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master;471
transformerLanguage;inference;SKX;fp32;Throughput;32;0.00;benchmark_transformerLanguage_inference_aipg-ra-skx-53_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master;471
transformerLanguage;inference;SKX;fp32;Latency;1;;benchmark_transformerLanguage_inference_aipg-ra-skx-53_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master;471
transformerSpeech;inference;SKX;fp32;Throughput;128;0.00;benchmark_transformerSpeech_inference_aipg-ra-skx-53_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master;471
transformerSpeech;inference;SKX;fp32;Latency;1;;benchmark_transformerSpeech_inference_aipg-ra-skx-53_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master;471
WaveNet;inference;SKX;fp32;Throughput;1;612.68;benchmark_WaveNet_inference_aipg-ra-skx-53_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master;471
WaveNet;inference;SKX;fp32;Latency;1;3.264365;benchmark_WaveNet_inference_aipg-ra-skx-53_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master;471
wideDeep;inference;SKX;fp32;Throughput;1024;86341.81;benchmark_wideDeep_inference_aipg-ra-skx-53_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master;471
wideDeep;inference;SKX;fp32;Latency;1;1.20;benchmark_wideDeep_inference_aipg-ra-skx-53_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master;471
WaveNet_Magenta;inference;SKX;fp32;Throughput;1;0.00;benchmark_WaveNet_Magenta_inference_aipg-ra-skx-53_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master;471
WaveNet_Magenta;inference;SKX;fp32;Latency;1;;benchmark_WaveNet_Magenta_inference_aipg-ra-skx-53_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master;471
UNet;inference;SKX;fp32;Latency;1;25.6417;benchmark_UNet_inference_aipg-ra-skx-53_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master;471
UNet;inference;SKX;fp32;Throughput;1;78.37;benchmark_UNet_inference_aipg-ra-skx-53_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master;471
YoloV2;inference;SKX;fp32;Throughput;8;79.80;benchmark_YoloV2_inference_aipg-ra-skx-53_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master;471
YoloV2;inference;SKX;fp32;Latency;1;29.3;benchmark_YoloV2_inference_aipg-ra-skx-53_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master;471
FastRCNN;inference;SKX;int8;Latency;1;87.1441;benchmark_FastRCNN_inference_aipg-ra-skx-54_throughput.log;Private-TensorFlow-Benchmark-Q3-Int8-Models;356
FastRCNN;inference;SKX;int8;Throughput;1;11.48;benchmark_FastRCNN_inference_aipg-ra-skx-54_throughput.log;Private-TensorFlow-Benchmark-Q3-Int8-Models;356
FastRCNN;inference;SKX;int8;Accuracy;1;0.309,0.477,;benchmark_FastRCNN_inference_aipg-ra-skx-54_accuracy.log;Private-TensorFlow-Benchmark-Q3-Int8-Models;356
YoloV2;inference;SKX;int8;Throughput;8;50.9;benchmark_YoloV2_inference_aipg-ra-skx-54_throughput.log;Private-TensorFlow-Benchmark-Q3-Int8-Models;356
YoloV2;inference;SKX;int8;Latency;1;24.4;benchmark_YoloV2_inference_aipg-ra-skx-54_latency.log;Private-TensorFlow-Benchmark-Q3-Int8-Models;356
YoloV2;inference;SKX;int8;Accuracy;1;;benchmark_YoloV2_inference_aipg-ra-skx-54_accuracy.log;Private-TensorFlow-Benchmark-Q3-Int8-Models;356
SSDMobilenet;inference;SKX;int8;Latency;1;15.5552;benchmark_SSDMobilenet_inference_aipg-ra-skx-54_throughput.log;Private-TensorFlow-Benchmark-Q3-Int8-Models;356
SSDMobilenet;inference;SKX;int8;Throughput;1;64.29;benchmark_SSDMobilenet_inference_aipg-ra-skx-54_throughput.log;Private-TensorFlow-Benchmark-Q3-Int8-Models;356
SSDMobilenet;inference;SKX;int8;Accuracy;1;0.188,0.288,;benchmark_SSDMobilenet_inference_aipg-ra-skx-54_accuracy.log;Private-TensorFlow-Benchmark-Q3-Int8-Models;356
SSD-VGG16;inference;SKX;int8;Throughput;224;;benchmark_SSD-VGG16_inference_aipg-ra-skx-54_throughput.log;Private-TensorFlow-Benchmark-Q3-Int8-Models;356
SSD-VGG16;inference;SKX;int8;Latency;1;;benchmark_SSD-VGG16_inference_aipg-ra-skx-54_latency.log;Private-TensorFlow-Benchmark-Q3-Int8-Models;356
SSD-VGG16;inference;SKX;int8;Accuracy;1;;benchmark_SSD-VGG16_inference_aipg-ra-skx-54_accuracy.log;Private-TensorFlow-Benchmark-Q3-Int8-Models;356
ResNet50;inference;SKX;int8;Throughput;128;543.674454119;benchmark_ResNet50_inference_aipg-ra-skx-54_throughput.log;Private-TensorFlow-Benchmark-Q3-Int8-Models;356
ResNet50;inference;SKX;int8;Latency;1;6.571;benchmark_ResNet50_inference_aipg-ra-skx-54_latency.log;Private-TensorFlow-Benchmark-Q3-Int8-Models;356
ResNet50;inference;SKX;int8;Accuracy;1;0.7377, 0.9164;benchmark_ResNet50_inference_aipg-ra-skx-54_accuracy.log;Private-TensorFlow-Benchmark-Q3-Int8-Models;356
InceptionV3;inference;SKX;int8;Throughput;128;387.907183355;benchmark_InceptionV3_inference_aipg-ra-skx-54_throughput.log;Private-TensorFlow-Benchmark-Q3-Int8-Models;356
InceptionV3;inference;SKX;int8;Latency;1;9.575;benchmark_InceptionV3_inference_aipg-ra-skx-54_latency.log;Private-TensorFlow-Benchmark-Q3-Int8-Models;356
InceptionV3;inference;SKX;int8;Accuracy;1;0.7651, 0.9335;benchmark_InceptionV3_inference_aipg-ra-skx-54_accuracy.log;Private-TensorFlow-Benchmark-Q3-Int8-Models;356
InceptionResNetV2;inference;SKX;int8;Throughput;128;137.496;benchmark_InceptionResNetV2_inference_aipg-ra-skx-54_throughput.log;Private-TensorFlow-Benchmark-Q3-Int8-Models;356
InceptionResNetV2;inference;SKX;int8;Latency;1;44.792;benchmark_InceptionResNetV2_inference_aipg-ra-skx-54_latency.log;Private-TensorFlow-Benchmark-Q3-Int8-Models;356
InceptionResNetV2;inference;SKX;int8;Accuracy;1;0.8015, 0.9526;benchmark_InceptionResNetV2_inference_aipg-ra-skx-54_accuracy.log;Private-TensorFlow-Benchmark-Q3-Int8-Models;356
mobilenetv1;inference;SKX;int8;Throughput;240;1853.01018699;benchmark_mobilenetv1_inference_aipg-ra-skx-54_throughput.log;Private-TensorFlow-Benchmark-Q3-Int8-Models;356
mobilenetv1;inference;SKX;int8;Latency;1;5.668;benchmark_mobilenetv1_inference_aipg-ra-skx-54_latency.log;Private-TensorFlow-Benchmark-Q3-Int8-Models;356
mobilenetv1;inference;SKX;int8;Accuracy;1;0.7014, 0.8934;benchmark_mobilenetv1_inference_aipg-ra-skx-54_accuracy.log;Private-TensorFlow-Benchmark-Q3-Int8-Models;356
RFCN;inference;SKX;int8;Latency;1;159.34;benchmark_RFCN_inference_aipg-ra-skx-54_throughput.log;Private-TensorFlow-Benchmark-Q3-Int8-Models;356
RFCN;inference;SKX;int8;Throughput;1;6.28;benchmark_RFCN_inference_aipg-ra-skx-54_throughput.log;Private-TensorFlow-Benchmark-Q3-Int8-Models;356
RFCN;inference;SKX;int8;Accuracy;1;32.70;benchmark_RFCN_inference_aipg-ra-skx-54_accuracy.log;Private-TensorFlow-Benchmark-Q3-Int8-Models;356
ssd_vgg16;inference;CLX;int8;Accuracy;1;0.231,0.386,;ssd_vgg16/benchmark_ssd_vgg16_inference_int8_accuracy_py3_aipg-ra-clx-106.log;Intel-Models-Benchmark-int8-py3-Trigger;109
ssd_vgg16;inference;SKX;int8;Accuracy;1;0.231,0.386,;ssd_vgg16/benchmark_ssd_vgg16_inference_int8_accuracy_py3_aipg-ra-skx-51.log;Intel-Models-Benchmark-int8-py3-Trigger;109
ssd_vgg16;inference;CLX;int8;Latency;1;35.913;ssd_vgg16/benchmark_ssd_vgg16_inference_int8_throughput_py3_aipg-ra-clx-106.log;Intel-Models-Benchmark-int8-py3-Trigger;109
ssd_vgg16;inference;CLX;int8;Throughput;1;27.845;ssd_vgg16/benchmark_ssd_vgg16_inference_int8_throughput_py3_aipg-ra-clx-106.log;Intel-Models-Benchmark-int8-py3-Trigger;109
ssd_vgg16;inference;SKX;int8;Latency;1;58.874;ssd_vgg16/benchmark_ssd_vgg16_inference_int8_throughput_py3_aipg-ra-skx-51.log;Intel-Models-Benchmark-int8-py3-Trigger;109
ssd_vgg16;inference;SKX;int8;Throughput;1;16.985;ssd_vgg16/benchmark_ssd_vgg16_inference_int8_throughput_py3_aipg-ra-skx-51.log;Intel-Models-Benchmark-int8-py3-Trigger;109
wide_deep_large_ds;inference;SKX;int8;Accuracy;1000;78.48;wide_deep_large_ds/benchmark_wide_deep_large_ds_inference_int8_accuracy_py3_aipg-ra-skx-52.log
wide_deep_large_ds;inference;CLX;int8;Accuracy;1000;78.48;wide_deep_large_ds/benchmark_wide_deep_large_ds_inference_int8_accuracy_py3_aipg-ra-clx-107.log
wide_deep_large_ds;inference;SKX;int8;Latency;1;3.36;wide_deep_large_ds/benchmark_wide_deep_large_ds_inference_int8_latency_py3_aipg-ra-skx-52.log
wide_deep_large_ds;inference;CLX;int8;Latency;1;3.27;wide_deep_large_ds/benchmark_wide_deep_large_ds_inference_int8_latency_py3_aipg-ra-clx-107.log
wide_deep_large_ds;inference;CLX;int8;Throughput;512;980478.376;wide_deep_large_ds/benchmark_wide_deep_large_ds_inference_int8_throughput_py3_aipg-ra-clx-107.log
wide_deep_large_ds;inference;SKX;int8;Throughput;512;740960.373;wide_deep_large_ds/benchmark_wide_deep_large_ds_inference_int8_throughput_py3_aipg-ra-skx-52.log
FastRCNN;inference;CLX;int8;Latency;1;59.9341;benchmark_FastRCNN_inference_aipg-ra-clx-108_throughput.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
FastRCNN;inference;CLX;int8;Throughput;1;16.68;benchmark_FastRCNN_inference_aipg-ra-clx-108_throughput.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
FastRCNN;inference;CLX;int8;Accuracy;1;0.309,0.477,;benchmark_FastRCNN_inference_aipg-ra-clx-108_accuracy.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
YoloV2;inference;CLX;int8;Throughput;8;54.8;benchmark_YoloV2_inference_aipg-ra-clx-108_throughput.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
YoloV2;inference;CLX;int8;Latency;1;22.7;benchmark_YoloV2_inference_aipg-ra-clx-108_latency.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
YoloV2;inference;CLX;int8;Accuracy;1;;benchmark_YoloV2_inference_aipg-ra-clx-108_accuracy.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
SSDMobilenet;inference;CLX;int8;Latency;1;13.5644;benchmark_SSDMobilenet_inference_aipg-ra-clx-108_throughput.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
SSDMobilenet;inference;CLX;int8;Throughput;1;73.72;benchmark_SSDMobilenet_inference_aipg-ra-clx-108_throughput.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
SSDMobilenet;inference;CLX;int8;Accuracy;1;0.218,0.331,;benchmark_SSDMobilenet_inference_aipg-ra-clx-108_accuracy.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
SSD-VGG16;inference;CLX;int8;Throughput;224;;benchmark_SSD-VGG16_inference_aipg-ra-clx-108_throughput.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
SSD-VGG16;inference;CLX;int8;Latency;1;;benchmark_SSD-VGG16_inference_aipg-ra-clx-108_latency.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
SSD-VGG16;inference;CLX;int8;Accuracy;1;;benchmark_SSD-VGG16_inference_aipg-ra-clx-108_accuracy.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
ResNet50;inference;CLX;int8;Throughput;128;1045.24021385;benchmark_ResNet50_inference_aipg-ra-clx-108_throughput.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
ResNet50;inference;CLX;int8;Latency;1;5.330;benchmark_ResNet50_inference_aipg-ra-clx-108_latency.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
ResNet50;inference;CLX;int8;Accuracy;1;0.7377, 0.9164;benchmark_ResNet50_inference_aipg-ra-clx-108_accuracy.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
InceptionV3;inference;CLX;int8;Throughput;128;793.380275696;benchmark_InceptionV3_inference_aipg-ra-clx-108_throughput.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
InceptionV3;inference;CLX;int8;Latency;1;7.803;benchmark_InceptionV3_inference_aipg-ra-clx-108_latency.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
InceptionV3;inference;CLX;int8;Accuracy;1;0.7652, 0.9335;benchmark_InceptionV3_inference_aipg-ra-clx-108_accuracy.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
InceptionResNetV2;inference;CLX;int8;Throughput;128;242.960;benchmark_InceptionResNetV2_inference_aipg-ra-clx-108_throughput.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
InceptionResNetV2;inference;CLX;int8;Latency;1;39.585;benchmark_InceptionResNetV2_inference_aipg-ra-clx-108_latency.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
InceptionResNetV2;inference;CLX;int8;Accuracy;1;0.8013, 0.9524;benchmark_InceptionResNetV2_inference_aipg-ra-clx-108_accuracy.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
mobilenetv1;inference;CLX;int8;Throughput;240;2543.0234867;benchmark_mobilenetv1_inference_aipg-ra-clx-108_throughput.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
mobilenetv1;inference;CLX;int8;Latency;1;5.090;benchmark_mobilenetv1_inference_aipg-ra-clx-108_latency.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
mobilenetv1;inference;CLX;int8;Accuracy;1;0.7013, 0.8934;benchmark_mobilenetv1_inference_aipg-ra-clx-108_accuracy.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
RFCN;inference;CLX;int8;Latency;1;133.88;benchmark_RFCN_inference_aipg-ra-clx-108_throughput.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
RFCN;inference;CLX;int8;Throughput;1;7.47;benchmark_RFCN_inference_aipg-ra-clx-108_throughput.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
RFCN;inference;CLX;int8;Accuracy;1;32.70;benchmark_RFCN_inference_aipg-ra-clx-108_accuracy.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
DenseNet;inference;CLX;fp32;Throughput;128;824.72;Q2_models_DenseNet_throughput.log;Private-TensorFlow-Benchmark-Q2-Py3-Master-CLX;295
DenseNet;inference;CLX;fp32;Latency;1;13.229609;Q2_models_DenseNet_latency.log;Private-TensorFlow-Benchmark-Q2-Py3-Master-CLX;295
3DUNet;inference;CLX;fp32;Throughput;1;;Q2_models_3DUNet_throughput.log;Private-TensorFlow-Benchmark-Q2-Py3-Master-CLX;295
3DUNet;inference;CLX;fp32;Latency;1;;Q2_models_3DUNet_latency.log;Private-TensorFlow-Benchmark-Q2-Py3-Master-CLX;295
MaskRCNN;inference;CLX;fp32;Throughput;1;3.33;Q2_models_MaskRCNN_throughput.log;Private-TensorFlow-Benchmark-Q2-Py3-Master-CLX;295
MaskRCNN;inference;CLX;fp32;Latency;1;591.0240;Q2_models_MaskRCNN_latency.log;Private-TensorFlow-Benchmark-Q2-Py3-Master-CLX;295
FaceNet;inference;SKX;fp32;Throughput;100;243.5892;benchmark_FaceNet_inference_aipg-ra-skx-53_throughput.log;Private-TensorFlow-Benchmark-Q4-FP32-Models;237
FaceNet;inference;SKX;fp32;Latency;1;31.1014;benchmark_FaceNet_inference_aipg-ra-skx-53_latency.log;Private-TensorFlow-Benchmark-Q4-FP32-Models;237
FaceNet;inference;SKX;fp32;Accuracy;1;0.98833+-0.00489;benchmark_FaceNet_inference_aipg-ra-skx-53_throughput.log;Private-TensorFlow-Benchmark-Q4-FP32-Models;237
MTCC;inference;SKX;fp32;Throughput;1;23.95;benchmark_MTCC_inference_aipg-ra-skx-53_throughput.log;Private-TensorFlow-Benchmark-Q4-FP32-Models;237
MTCC;inference;SKX;fp32;Latency;1;41.75;benchmark_MTCC_inference_aipg-ra-skx-53_throughput.log;Private-TensorFlow-Benchmark-Q4-FP32-Models;237
MTCC;inference;SKX;fp32;Accuracy;1;1.12;benchmark_MTCC_inference_aipg-ra-skx-53_throughput.log;Private-TensorFlow-Benchmark-Q4-FP32-Models;237
DenseNet169;inference;SKX;fp32;Throughput;100;160.266856078;benchmark_DenseNet169_inference_aipg-ra-skx-53_throughput.log;Private-TensorFlow-Benchmark-Q4-FP32-Models;237
DenseNet169;inference;SKX;fp32;Latency;1;27.082927227;benchmark_DenseNet169_inference_aipg-ra-skx-53_latency.log;Private-TensorFlow-Benchmark-Q4-FP32-Models;237
DenseNet169;inference;SKX;fp32;Accuracy;100;0.75748;benchmark_DenseNet169_inference_aipg-ra-skx-53_accuracy.log;Private-TensorFlow-Benchmark-Q4-FP32-Models;237
ResNet101;inference;SKX;fp32;Throughput;128;150.583072193;benchmark_ResNet101_inference_aipg-ra-skx-53_throughput.log;Private-TensorFlow-Benchmark-Q4-FP32-Models;237
ResNet101;inference;SKX;fp32;Latency;1;18.353;benchmark_ResNet101_inference_aipg-ra-skx-53_latency.log;Private-TensorFlow-Benchmark-Q4-FP32-Models;237
ResNet101;inference;SKX;fp32;Accuracy;1;0.7640, 0.9289;benchmark_ResNet101_inference_aipg-ra-skx-53_accuracy.log;Private-TensorFlow-Benchmark-Q4-FP32-Models;237
SSDMobilenet;inference;SKX;fp32;Throughput;1;24.69;benchmark_SSDMobilenet_inference_aipg-ra-skx-53_throughput.log;Private-TensorFlow-Benchmark-Q4-FP32-Models;237
SSDMobilenet;inference;SKX;fp32;Latency;1;40.5;benchmark_SSDMobilenet_inference_aipg-ra-skx-53_throughput.log;Private-TensorFlow-Benchmark-Q4-FP32-Models;237
FaceNet;inference;CLX;fp32;Throughput;100;219.5861;benchmark_FaceNet_inference_aipg-ra-clx-100_throughput.log;Private-TensorFlow-Benchmark-Q4-FP32-Models-CLX;228
FaceNet;inference;CLX;fp32;Latency;1;29.8184;benchmark_FaceNet_inference_aipg-ra-clx-100_latency.log;Private-TensorFlow-Benchmark-Q4-FP32-Models-CLX;228
FaceNet;inference;CLX;fp32;Accuracy;1;0.98833+-0.00489;benchmark_FaceNet_inference_aipg-ra-clx-100_throughput.log;Private-TensorFlow-Benchmark-Q4-FP32-Models-CLX;228
MTCC;inference;CLX;fp32;Throughput;1;24.65;benchmark_MTCC_inference_aipg-ra-clx-100_throughput.log;Private-TensorFlow-Benchmark-Q4-FP32-Models-CLX;228
MTCC;inference;CLX;fp32;Latency;1;40.57;benchmark_MTCC_inference_aipg-ra-clx-100_throughput.log;Private-TensorFlow-Benchmark-Q4-FP32-Models-CLX;228
MTCC;inference;CLX;fp32;Accuracy;1;1.12;benchmark_MTCC_inference_aipg-ra-clx-100_throughput.log;Private-TensorFlow-Benchmark-Q4-FP32-Models-CLX;228
DenseNet169;inference;CLX;fp32;Throughput;100;170.016246603;benchmark_DenseNet169_inference_aipg-ra-clx-100_throughput.log;Private-TensorFlow-Benchmark-Q4-FP32-Models-CLX;228
DenseNet169;inference;CLX;fp32;Latency;1;26.1639547348;benchmark_DenseNet169_inference_aipg-ra-clx-100_latency.log;Private-TensorFlow-Benchmark-Q4-FP32-Models-CLX;228
DenseNet169;inference;CLX;fp32;Accuracy;100;0.75748;benchmark_DenseNet169_inference_aipg-ra-clx-100_accuracy.log;Private-TensorFlow-Benchmark-Q4-FP32-Models-CLX;228
ResNet101;inference;CLX;fp32;Throughput;128;154.441866477;benchmark_ResNet101_inference_aipg-ra-clx-100_throughput.log;Private-TensorFlow-Benchmark-Q4-FP32-Models-CLX;228
ResNet101;inference;CLX;fp32;Latency;1;17.127;benchmark_ResNet101_inference_aipg-ra-clx-100_latency.log;Private-TensorFlow-Benchmark-Q4-FP32-Models-CLX;228
ResNet101;inference;CLX;fp32;Accuracy;1;0.7640, 0.9289;benchmark_ResNet101_inference_aipg-ra-clx-100_accuracy.log;Private-TensorFlow-Benchmark-Q4-FP32-Models-CLX;228
SSDMobilenet;inference;CLX;fp32;Throughput;1;26.67;benchmark_SSDMobilenet_inference_aipg-ra-clx-100_throughput.log;Private-TensorFlow-Benchmark-Q4-FP32-Models-CLX;228
SSDMobilenet;inference;CLX;fp32;Latency;1;37.5;benchmark_SSDMobilenet_inference_aipg-ra-clx-100_throughput.log;Private-TensorFlow-Benchmark-Q4-FP32-Models-CLX;228
maskrcnn;inference;CLX;fp32;Latency;1;610.0455;maskrcnn/benchmark_maskrcnn_inference_fp32_throughput_py3_aipg-ra-clx-107.log;Intel-Models-Benchmark-fp32-py3-Trigger;114
maskrcnn;inference;CLX;fp32;Throughput;1;1.6392;maskrcnn/benchmark_maskrcnn_inference_fp32_throughput_py3_aipg-ra-clx-107.log;Intel-Models-Benchmark-fp32-py3-Trigger;114
maskrcnn;inference;SKX;fp32;Latency;1;632.0872;maskrcnn/benchmark_maskrcnn_inference_fp32_throughput_py3_aipg-ra-skx-54.log;Intel-Models-Benchmark-fp32-py3-Trigger;114
maskrcnn;inference;SKX;fp32;Throughput;1;1.5821;maskrcnn/benchmark_maskrcnn_inference_fp32_throughput_py3_aipg-ra-skx-54.log;Intel-Models-Benchmark-fp32-py3-Trigger;114
ssd_vgg16;inference;CLX;fp32;Accuracy;1;0.236,0.391,;ssd_vgg16/benchmark_ssd_vgg16_inference_fp32_accuracy_py3_aipg-ra-clx-91.log;Intel-Models-Benchmark-fp32-py3-Trigger;114
ssd_vgg16;inference;SKX;fp32;Accuracy;1;;ssd_vgg16/benchmark_ssd_vgg16_inference_fp32_accuracy_py3_aipg-ra-skx-53.log;Intel-Models-Benchmark-fp32-py3-Trigger;114
ssd_vgg16;inference;CLX;fp32;Latency;1;66.921;ssd_vgg16/benchmark_ssd_vgg16_inference_fp32_throughput_py3_aipg-ra-clx-91.log;Intel-Models-Benchmark-fp32-py3-Trigger;114
ssd_vgg16;inference;CLX;fp32;Throughput;1;14.943;ssd_vgg16/benchmark_ssd_vgg16_inference_fp32_throughput_py3_aipg-ra-clx-91.log;Intel-Models-Benchmark-fp32-py3-Trigger;114
ssd_vgg16;inference;SKX;fp32;Latency;1;;ssd_vgg16/benchmark_ssd_vgg16_inference_fp32_throughput_py3_aipg-ra-skx-53.log;Intel-Models-Benchmark-fp32-py3-Trigger;114
ssd_vgg16;inference;SKX;fp32;Throughput;1;;ssd_vgg16/benchmark_ssd_vgg16_inference_fp32_throughput_py3_aipg-ra-skx-53.log;Intel-Models-Benchmark-fp32-py3-Trigger;114
wide_deep_large_ds;inference;SKX;fp32;Accuracy;1000;78.52;wide_deep_large_ds/benchmark_wide_deep_large_ds_inference_fp32_accuracy_py3_aipg-ra-skx-54.log
wide_deep_large_ds;inference;CLX;fp32;Accuracy;1000;78.52;wide_deep_large_ds/benchmark_wide_deep_large_ds_inference_fp32_accuracy_py3_aipg-ra-clx-105.log
wide_deep_large_ds;inference;CLX;fp32;Latency;1;1.85;wide_deep_large_ds/benchmark_wide_deep_large_ds_inference_fp32_latency_py3_aipg-ra-clx-105.log
wide_deep_large_ds;inference;SKX;fp32;Latency;1;2.02;wide_deep_large_ds/benchmark_wide_deep_large_ds_inference_fp32_latency_py3_aipg-ra-skx-54.log
wide_deep_large_ds;inference;SKX;fp32;Throughput;512;540343.705;wide_deep_large_ds/benchmark_wide_deep_large_ds_inference_fp32_throughput_py3_aipg-ra-skx-54.log
wide_deep_large_ds;inference;CLX;fp32;Throughput;512;581815.912;wide_deep_large_ds/benchmark_wide_deep_large_ds_inference_fp32_throughput_py3_aipg-ra-clx-105.log
