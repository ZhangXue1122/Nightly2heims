3DGAN;inference;CLX;fp32;Throughput;;0.00;benchmark_3DGAN_inference_aipg-ra-clx-88_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
A3C;inference;CLX;fp32;Latency;1;2.3609;benchmark_A3C_inference_aipg-ra-clx-88_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
A3C;inference;CLX;fp32;Throughput;1;870.25;benchmark_A3C_inference_aipg-ra-clx-88_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
DCGAN;inference;CLX;fp32;Throughput;;0.00;benchmark_DCGAN_inference_aipg-ra-clx-88_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
deepSpeech;inference;CLX;fp32;Throughput;1;0.00;benchmark_deepSpeech_inference_aipg-ra-clx-88_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
deepSpeech;inference;CLX;fp32;Latency;1;;benchmark_deepSpeech_inference_aipg-ra-clx-88_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
DRAW;inference;CLX;fp32;Latency;;;benchmark_DRAW_inference_aipg-ra-clx-88_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
DRAW;inference;CLX;fp32;Throughput;;0.00;benchmark_DRAW_inference_aipg-ra-clx-88_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
fastrcnn;training;CLX;fp32;Latency;1;363.497;benchmark_fastrcnn_training_aipg-ra-clx-88_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
fastrcnn;training;CLX;fp32;Throughput;1;2.75;benchmark_fastrcnn_training_aipg-ra-clx-88_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
fastrcnn;inference;CLX;fp32;Throughput;1;10.52;benchmark_fastrcnn_inference_aipg-ra-clx-88_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
fastrcnn;inference;CLX;fp32;Latency;1;0.190;benchmark_fastrcnn_inference_aipg-ra-clx-88_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
gnmt;inference;CLX;fp32;Throughput;32;29.94;benchmark_gnmt_inference_aipg-ra-clx-88_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
gnmt;inference;CLX;fp32;Latency;1;295.9733;benchmark_gnmt_inference_aipg-ra-clx-88_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
inception_resnet_v2;inference;CLX;fp32;Throughput;128;77.40;benchmark_inception_resnet_v2_inference_aipg-ra-clx-88_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
inception_resnet_v2;inference;CLX;fp32;Latency;1;62.7;benchmark_inception_resnet_v2_inference_aipg-ra-clx-88_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
inceptionv3;inference;CLX;fp32;Throughput;128;448.34;benchmark_inceptionv3_inference_aipg-ra-clx-88_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
inceptionv3;inference;CLX;fp32;Latency;1;10.692;benchmark_inceptionv3_inference_aipg-ra-clx-88_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
inception_v4;inference;CLX;fp32;Throughput;128;149.20;benchmark_inception_v4_inference_aipg-ra-clx-88_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
inception_v4;inference;CLX;fp32;Latency;1;30.2;benchmark_inception_v4_inference_aipg-ra-clx-88_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
mobilenet_v1;inference;CLX;fp32;Throughput;100;608.00;benchmark_mobilenet_v1_inference_aipg-ra-clx-88_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
mobilenet_v1;inference;CLX;fp32;Latency;1;5.9;benchmark_mobilenet_v1_inference_aipg-ra-clx-88_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
resnet50;inference;CLX;fp32;Throughput;128;650.38;benchmark_resnet50_inference_aipg-ra-clx-88_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
resnet50;inference;CLX;fp32;Latency;1;6.750;benchmark_resnet50_inference_aipg-ra-clx-88_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
rfcn;inference;CLX;fp32;Throughput;1;7.12;benchmark_rfcn_inference_aipg-ra-clx-88_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
rfcn;inference;CLX;fp32;Latency;1;281;benchmark_rfcn_inference_aipg-ra-clx-88_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
SqueezeNet;inference;CLX;fp32;Throughput;64;1682.60;benchmark_SqueezeNet_inference_aipg-ra-clx-88_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
SqueezeNet;inference;CLX;fp32;Latency;1;6.255;benchmark_SqueezeNet_inference_aipg-ra-clx-88_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
transformerLanguage;inference;CLX;fp32;Throughput;32;0.00;benchmark_transformerLanguage_inference_aipg-ra-clx-88_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
transformerLanguage;inference;CLX;fp32;Latency;1;;benchmark_transformerLanguage_inference_aipg-ra-clx-88_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
transformerSpeech;inference;CLX;fp32;Throughput;128;0.00;benchmark_transformerSpeech_inference_aipg-ra-clx-88_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
transformerSpeech;inference;CLX;fp32;Latency;1;;benchmark_transformerSpeech_inference_aipg-ra-clx-88_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
WaveNet;inference;CLX;fp32;Throughput;1;599.99;benchmark_WaveNet_inference_aipg-ra-clx-88_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
WaveNet;inference;CLX;fp32;Latency;1;3.333377;benchmark_WaveNet_inference_aipg-ra-clx-88_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
wideDeep;inference;CLX;fp32;Throughput;1024;84553.84;benchmark_wideDeep_inference_aipg-ra-clx-88_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
wideDeep;inference;CLX;fp32;Latency;1;1.16;benchmark_wideDeep_inference_aipg-ra-clx-88_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
WaveNet_Magenta;inference;CLX;fp32;Throughput;1;0.00;benchmark_WaveNet_Magenta_inference_aipg-ra-clx-88_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
WaveNet_Magenta;inference;CLX;fp32;Latency;1;;benchmark_WaveNet_Magenta_inference_aipg-ra-clx-88_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
UNet;inference;CLX;fp32;Latency;1;22.8464;benchmark_UNet_inference_aipg-ra-clx-88_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
UNet;inference;CLX;fp32;Throughput;1;78.78;benchmark_UNet_inference_aipg-ra-clx-88_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
YoloV2;inference;CLX;fp32;Throughput;8;80.00;benchmark_YoloV2_inference_aipg-ra-clx-88_throughput.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
YoloV2;inference;CLX;fp32;Latency;1;26.5;benchmark_YoloV2_inference_aipg-ra-clx-88_latency.log;Private-TensorFlow-Benchmark-Q2-Py2-Master-CLX;293
NCF;inference;CLX;fp32;Throughput;256;1220726.20;benchmark_NCF_inference_aipg-ra-clx-90_throughput.log;Private-TensorFlow-Benchmark-Q3-FP32-Models-CLX;312
NCF;inference;CLX;fp32;Latency;1;0.293;benchmark_NCF_inference_aipg-ra-clx-90_latency.log;Private-TensorFlow-Benchmark-Q3-FP32-Models-CLX;312
Wide_Deep_Census;training;CLX;fp32;Accuracy;40;1.01.0;benchmark_Wide_Deep_Census_training_aipg-ra-clx-90_throughput.log;Private-TensorFlow-Benchmark-Q3-FP32-Models-CLX;312
Wide_Deep_Census;training;CLX;fp32;Throughput;40;10020.9602955;benchmark_Wide_Deep_Census_training_aipg-ra-clx-90_throughput.log;Private-TensorFlow-Benchmark-Q3-FP32-Models-CLX;312
Wide_Deep_Criteo;training;CLX;fp32;Accuracy;128;;benchmark_Wide_Deep_Criteo_training_aipg-ra-clx-90_throughput.log;Private-TensorFlow-Benchmark-Q3-FP32-Models-CLX;312
Wide_Deep_Criteo;training;CLX;fp32;Throughput;128;;benchmark_Wide_Deep_Criteo_training_aipg-ra-clx-90_throughput.log;Private-TensorFlow-Benchmark-Q3-FP32-Models-CLX;312
MobileNet_v1;training;CLX;fp32;Throughput;64;189.4507;benchmark_MobileNet_v1_training_aipg-ra-clx-90_throughput.log;Private-TensorFlow-Benchmark-Q3-FP32-Models-CLX;312
Inception_ResNet_v2;training;CLX;fp32;Throughput;64;11.8954;benchmark_Inception_ResNet_v2_training_aipg-ra-clx-90_throughput.log;Private-TensorFlow-Benchmark-Q3-FP32-Models-CLX;312
ResNet101;inference;CLX;int8;Throughput;128;614.231137048;benchmark_ResNet101_inference_aipg-ra-clx-89_throughput.log;Private-TensorFlow-Benchmark-Q4-Int8-Models-CLX;224
ResNet101;inference;CLX;int8;Latency;1;11.151;benchmark_ResNet101_inference_aipg-ra-clx-89_latency.log;Private-TensorFlow-Benchmark-Q4-Int8-Models-CLX;224
ResNet101;inference;CLX;int8;Accuracy;1;0.7578, 0.9260;benchmark_ResNet101_inference_aipg-ra-clx-89_accuracy.log;Private-TensorFlow-Benchmark-Q4-Int8-Models-CLX;224
InceptionV4;inference;CLX;int8;Throughput;240;336.989668689;benchmark_InceptionV4_inference_aipg-ra-clx-89_throughput.log;Private-TensorFlow-Benchmark-Q4-Int8-Models-CLX;224
InceptionV4;inference;CLX;int8;Latency;1;19.946;benchmark_InceptionV4_inference_aipg-ra-clx-89_latency.log;Private-TensorFlow-Benchmark-Q4-Int8-Models-CLX;224
InceptionV4;inference;CLX;int8;Accuracy;1;0.7988, 0.9504;benchmark_InceptionV4_inference_aipg-ra-clx-89_accuracy.log;Private-TensorFlow-Benchmark-Q4-Int8-Models-CLX;224
wide_deep_large_ds;inference;CLX;int8;Accuracy;1000;78.48;wide_deep_large_ds/benchmark_wide_deep_large_ds_inference_int8_accuracy_py3_aipg-ra-clx-107.log
wide_deep_large_ds;inference;CLX;int8;Latency;1;3.27;wide_deep_large_ds/benchmark_wide_deep_large_ds_inference_int8_latency_py3_aipg-ra-clx-107.log
wide_deep_large_ds;inference;CLX;int8;Throughput;512;980478.376;wide_deep_large_ds/benchmark_wide_deep_large_ds_inference_int8_throughput_py3_aipg-ra-clx-107.log
FastRCNN;inference;CLX;int8;Latency;1;59.9341;benchmark_FastRCNN_inference_aipg-ra-clx-108_throughput.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
FastRCNN;inference;CLX;int8;Throughput;1;16.68;benchmark_FastRCNN_inference_aipg-ra-clx-108_throughput.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
FastRCNN;inference;CLX;int8;Accuracy;1;0.309,0.477,;benchmark_FastRCNN_inference_aipg-ra-clx-108_accuracy.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
YoloV2;inference;CLX;int8;Throughput;8;54.8;benchmark_YoloV2_inference_aipg-ra-clx-108_throughput.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
YoloV2;inference;CLX;int8;Latency;1;22.7;benchmark_YoloV2_inference_aipg-ra-clx-108_latency.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
YoloV2;inference;CLX;int8;Accuracy;1;;benchmark_YoloV2_inference_aipg-ra-clx-108_accuracy.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
SSDMobilenet;inference;CLX;int8;Latency;1;13.5644;benchmark_SSDMobilenet_inference_aipg-ra-clx-108_throughput.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
SSDMobilenet;inference;CLX;int8;Throughput;1;73.72;benchmark_SSDMobilenet_inference_aipg-ra-clx-108_throughput.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
SSDMobilenet;inference;CLX;int8;Accuracy;1;0.218,0.331,;benchmark_SSDMobilenet_inference_aipg-ra-clx-108_accuracy.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
SSD-VGG16;inference;CLX;int8;Throughput;224;;benchmark_SSD-VGG16_inference_aipg-ra-clx-108_throughput.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
SSD-VGG16;inference;CLX;int8;Latency;1;;benchmark_SSD-VGG16_inference_aipg-ra-clx-108_latency.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
SSD-VGG16;inference;CLX;int8;Accuracy;1;;benchmark_SSD-VGG16_inference_aipg-ra-clx-108_accuracy.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
ResNet50;inference;CLX;int8;Throughput;128;1045.24021385;benchmark_ResNet50_inference_aipg-ra-clx-108_throughput.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
ResNet50;inference;CLX;int8;Latency;1;5.330;benchmark_ResNet50_inference_aipg-ra-clx-108_latency.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
ResNet50;inference;CLX;int8;Accuracy;1;0.7377, 0.9164;benchmark_ResNet50_inference_aipg-ra-clx-108_accuracy.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
InceptionV3;inference;CLX;int8;Throughput;128;793.380275696;benchmark_InceptionV3_inference_aipg-ra-clx-108_throughput.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
InceptionV3;inference;CLX;int8;Latency;1;7.803;benchmark_InceptionV3_inference_aipg-ra-clx-108_latency.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
InceptionV3;inference;CLX;int8;Accuracy;1;0.7652, 0.9335;benchmark_InceptionV3_inference_aipg-ra-clx-108_accuracy.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
InceptionResNetV2;inference;CLX;int8;Throughput;128;242.960;benchmark_InceptionResNetV2_inference_aipg-ra-clx-108_throughput.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
InceptionResNetV2;inference;CLX;int8;Latency;1;39.585;benchmark_InceptionResNetV2_inference_aipg-ra-clx-108_latency.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
InceptionResNetV2;inference;CLX;int8;Accuracy;1;0.8013, 0.9524;benchmark_InceptionResNetV2_inference_aipg-ra-clx-108_accuracy.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
mobilenetv1;inference;CLX;int8;Throughput;240;2543.0234867;benchmark_mobilenetv1_inference_aipg-ra-clx-108_throughput.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
mobilenetv1;inference;CLX;int8;Latency;1;5.090;benchmark_mobilenetv1_inference_aipg-ra-clx-108_latency.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
mobilenetv1;inference;CLX;int8;Accuracy;1;0.7013, 0.8934;benchmark_mobilenetv1_inference_aipg-ra-clx-108_accuracy.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
RFCN;inference;CLX;int8;Latency;1;133.88;benchmark_RFCN_inference_aipg-ra-clx-108_throughput.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
RFCN;inference;CLX;int8;Throughput;1;7.47;benchmark_RFCN_inference_aipg-ra-clx-108_throughput.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
RFCN;inference;CLX;int8;Accuracy;1;32.70;benchmark_RFCN_inference_aipg-ra-clx-108_accuracy.log;Private-TensorFlow-Benchmark-Q3-Int8-Models-CLX;303
DenseNet;inference;CLX;fp32;Throughput;128;824.72;Q2_models_DenseNet_throughput.log;Private-TensorFlow-Benchmark-Q2-Py3-Master-CLX;295
DenseNet;inference;CLX;fp32;Latency;1;13.229609;Q2_models_DenseNet_latency.log;Private-TensorFlow-Benchmark-Q2-Py3-Master-CLX;295
3DUNet;inference;CLX;fp32;Throughput;1;;Q2_models_3DUNet_throughput.log;Private-TensorFlow-Benchmark-Q2-Py3-Master-CLX;295
3DUNet;inference;CLX;fp32;Latency;1;;Q2_models_3DUNet_latency.log;Private-TensorFlow-Benchmark-Q2-Py3-Master-CLX;295
MaskRCNN;inference;CLX;fp32;Throughput;1;3.33;Q2_models_MaskRCNN_throughput.log;Private-TensorFlow-Benchmark-Q2-Py3-Master-CLX;295
MaskRCNN;inference;CLX;fp32;Latency;1;591.0240;Q2_models_MaskRCNN_latency.log;Private-TensorFlow-Benchmark-Q2-Py3-Master-CLX;295
FaceNet;inference;CLX;fp32;Throughput;100;219.5861;benchmark_FaceNet_inference_aipg-ra-clx-100_throughput.log;Private-TensorFlow-Benchmark-Q4-FP32-Models-CLX;228
FaceNet;inference;CLX;fp32;Latency;1;29.8184;benchmark_FaceNet_inference_aipg-ra-clx-100_latency.log;Private-TensorFlow-Benchmark-Q4-FP32-Models-CLX;228
FaceNet;inference;CLX;fp32;Accuracy;1;0.98833+-0.00489;benchmark_FaceNet_inference_aipg-ra-clx-100_throughput.log;Private-TensorFlow-Benchmark-Q4-FP32-Models-CLX;228
MTCC;inference;CLX;fp32;Throughput;1;24.65;benchmark_MTCC_inference_aipg-ra-clx-100_throughput.log;Private-TensorFlow-Benchmark-Q4-FP32-Models-CLX;228
MTCC;inference;CLX;fp32;Latency;1;40.57;benchmark_MTCC_inference_aipg-ra-clx-100_throughput.log;Private-TensorFlow-Benchmark-Q4-FP32-Models-CLX;228
MTCC;inference;CLX;fp32;Accuracy;1;1.12;benchmark_MTCC_inference_aipg-ra-clx-100_throughput.log;Private-TensorFlow-Benchmark-Q4-FP32-Models-CLX;228
DenseNet169;inference;CLX;fp32;Throughput;100;170.016246603;benchmark_DenseNet169_inference_aipg-ra-clx-100_throughput.log;Private-TensorFlow-Benchmark-Q4-FP32-Models-CLX;228
DenseNet169;inference;CLX;fp32;Latency;1;26.1639547348;benchmark_DenseNet169_inference_aipg-ra-clx-100_latency.log;Private-TensorFlow-Benchmark-Q4-FP32-Models-CLX;228
DenseNet169;inference;CLX;fp32;Accuracy;100;0.75748;benchmark_DenseNet169_inference_aipg-ra-clx-100_accuracy.log;Private-TensorFlow-Benchmark-Q4-FP32-Models-CLX;228
ResNet101;inference;CLX;fp32;Throughput;128;154.441866477;benchmark_ResNet101_inference_aipg-ra-clx-100_throughput.log;Private-TensorFlow-Benchmark-Q4-FP32-Models-CLX;228
ResNet101;inference;CLX;fp32;Latency;1;17.127;benchmark_ResNet101_inference_aipg-ra-clx-100_latency.log;Private-TensorFlow-Benchmark-Q4-FP32-Models-CLX;228
ResNet101;inference;CLX;fp32;Accuracy;1;0.7640, 0.9289;benchmark_ResNet101_inference_aipg-ra-clx-100_accuracy.log;Private-TensorFlow-Benchmark-Q4-FP32-Models-CLX;228
SSDMobilenet;inference;CLX;fp32;Throughput;1;26.67;benchmark_SSDMobilenet_inference_aipg-ra-clx-100_throughput.log;Private-TensorFlow-Benchmark-Q4-FP32-Models-CLX;228
SSDMobilenet;inference;CLX;fp32;Latency;1;37.5;benchmark_SSDMobilenet_inference_aipg-ra-clx-100_throughput.log;Private-TensorFlow-Benchmark-Q4-FP32-Models-CLX;228
wide_deep_large_ds;inference;CLX;fp32;Accuracy;1000;78.52;wide_deep_large_ds/benchmark_wide_deep_large_ds_inference_fp32_accuracy_py3_aipg-ra-clx-105.log
wide_deep_large_ds;inference;CLX;fp32;Latency;1;1.85;wide_deep_large_ds/benchmark_wide_deep_large_ds_inference_fp32_latency_py3_aipg-ra-clx-105.log
wide_deep_large_ds;inference;CLX;fp32;Throughput;512;581815.912;wide_deep_large_ds/benchmark_wide_deep_large_ds_inference_fp32_throughput_py3_aipg-ra-clx-105.log
